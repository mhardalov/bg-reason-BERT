{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SlavicBert-RACE.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqCdgzsI6eXB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%sh\n",
        "git clone https://github.com/NVIDIA/apex\n",
        "pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./apex\n",
        "\n",
        "pip install torchvision torch\n",
        "pip install pytorch_pretrained_bert"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IW1FWetPFLOe",
        "colab_type": "text"
      },
      "source": [
        "Installing some prerequisites"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8SZ39kN27UU",
        "colab_type": "text"
      },
      "source": [
        "Downloading BERT-RACE and the Slavic-BERT:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaJizy-S27oA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%sh\n",
        "git clone https://github.com/NoviScl/BERT-RACE.git\n",
        "wget http://www.cs.cmu.edu/~glai1/data/race/RACE.tar.gz -O RACE.tar.gz\n",
        "wget http://files.deeppavlov.ai/deeppavlov_data/bert/bg_cs_pl_ru_cased_L-12_H-768_A-12.tar.gz\n",
        "tar -xzvf RACE.tar.gz\n",
        "tar -xzvf bg_cs_pl_ru_cased_L-12_H-768_A-12.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfYEs7tkFGqc",
        "colab_type": "text"
      },
      "source": [
        "Converting the tensorflow model to a pytorch model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9pgpNXW8hYv",
        "colab_type": "code",
        "outputId": "3a0b0761-96bd-476e-f3cd-ed7c5a3b8a54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "%%sh\n",
        "export BERT_BASE_DIR=./bg_cs_pl_ru_cased_L-12_H-768_A-12\n",
        "\n",
        "pytorch_pretrained_bert convert_tf_checkpoint_to_pytorch \\\n",
        "  $BERT_BASE_DIR/bert_model.ckpt.index \\\n",
        "  $BERT_BASE_DIR/bert_config.json \\\n",
        "  $BERT_BASE_DIR/pytorch_model.bin\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building PyTorch model from configuration: {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"directionality\": \"bidi\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pooler_fc_size\": 768,\n",
            "  \"pooler_num_attention_heads\": 12,\n",
            "  \"pooler_num_fc_layers\": 3,\n",
            "  \"pooler_size_per_head\": 128,\n",
            "  \"pooler_type\": \"first_token_transform\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 119547\n",
            "}\n",
            "\n",
            "Converting TensorFlow checkpoint from /content/bg_cs_pl_ru_cased_L-12_H-768_A-12/bert_model.ckpt.index\n",
            "Save PyTorch model to ./bg_cs_pl_ru_cased_L-12_H-768_A-12/pytorch_model.bin\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjdcCPKY3zwY",
        "colab_type": "code",
        "outputId": "a0d46079-bb57-44b7-8dc2-d2cb52c91337",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3398
        }
      },
      "source": [
        "!python BERT-RACE/run_race.py --data_dir=RACE --bert_model=bg_cs_pl_ru_cased_L-12_H-768_A-12/ --output_dir=./slavic_models_3_epochs_1e-5 --max_seq_length=320 --do_train --do_eval --train_batch_size=32 --eval_batch_size=1 --learning_rate=1e-5 --num_train_epochs=3 --gradient_accumulation_steps=8 --fp16 --loss_scale=128"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "06/12/2019 21:01:31 - INFO - __main__ -   device: cuda n_gpu: 1, distributed training: False, 16-bits training: True\n",
            "06/12/2019 21:01:31 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file bg_cs_pl_ru_cased_L-12_H-768_A-12/vocab.txt\n",
            "06/12/2019 21:01:35 - INFO - pytorch_pretrained_bert.modeling -   loading archive file bg_cs_pl_ru_cased_L-12_H-768_A-12/\n",
            "06/12/2019 21:01:35 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"directionality\": \"bidi\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pooler_fc_size\": 768,\n",
            "  \"pooler_num_attention_heads\": 12,\n",
            "  \"pooler_num_fc_layers\": 3,\n",
            "  \"pooler_size_per_head\": 128,\n",
            "  \"pooler_type\": \"first_token_transform\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 119547\n",
            "}\n",
            "\n",
            "06/12/2019 21:01:41 - INFO - pytorch_pretrained_bert.modeling -   Weights of BertForMultipleChoice not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
            "06/12/2019 21:01:41 - INFO - pytorch_pretrained_bert.modeling -   Weights from pretrained model not used in BertForMultipleChoice: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "06/12/2019 21:01:46 - INFO - __main__ -   *** Example ***\n",
            "06/12/2019 21:01:46 - INFO - __main__ -   race_id: RACE/train/high/1705.txt-0\n",
            "06/12/2019 21:01:46 - INFO - __main__ -   choice: 0\n",
            "06/12/2019 21:01:46 - INFO - __main__ -   tokens: [CLS] In the e ##arl ##y 1990 ##s , the wor ##d \" Internet \" was stran ##ge to most people . But to ##day , Internet has be ##come a us ##ef ##ul to ##ol for people all over the world . May ##be Internet has be ##en the gre ##ates ##t invent ##ion in the field of commu ##nica ##tion in the history of man ##kin ##d . Communic ##ating with ot ##her ##s on the Internet is much fast ##er . We can chat with a person wh ##o is sit ##ting in the ot ##her part of the world . We can e - mail our fr ##ien ##ds and the ##y can re ##ad the e - mail ##s with ##in a minut ##e . Giv ##ing all kin ##ds of informa ##tion is prob ##ab ##ly the big ##gest ad ##van ##tage of the Internet . We can us ##e se ##arch engine ##s to fin ##d the informa ##tion we ne ##ed . Just type in a key ##wor ##d or key ##wor ##ds and the se ##arch engine will gi ##ve us a list of sui ##table web ##sit ##es to lo ##ok at . We can en ##jo ##y a lot on the Internet by down ##load ##ing game ##s , vis ##iti ##ng chat ro ##oms or sur ##fing web ##sit ##es . There are som ##e game ##s for free . We can me ##et new and interes ##ting people in the chat now . We can al ##so list ##en to music and se ##e film ##s . Now , the ##re is a lot of service on the Internet such as online banki ##ng , jo ##b fin ##ding and ti [SEP] How man ##y main ad ##van ##tage ##s of the Internet are talk ##ed ab ##out in the _ pas ##sage ? Three . [SEP]\n",
            "06/12/2019 21:01:46 - INFO - __main__ -   input_ids: 101 2762 5139 173 43278 405 3692 316 117 5139 39360 376 107 12416 107 10134 3459 3175 2332 7821 11426 119 16976 2332 24558 117 12416 10393 10347 61643 169 5097 3756 2355 2332 2098 2767 11426 10435 10491 5139 11356 119 10725 5446 12416 10393 10347 2016 5139 39819 26171 312 100910 5165 2283 5139 13939 3520 106036 6339 2120 2283 5139 11486 3520 5058 12130 376 119 64336 33121 10169 3033 4806 316 4467 5139 12416 10124 13172 15040 2030 119 5505 10944 50915 10169 169 15042 101396 203 10124 19285 12141 2283 5139 3033 4806 8647 3520 5139 11356 119 5505 10944 173 118 30049 17446 12127 3579 13268 6449 5139 405 10944 2261 2070 5139 173 118 30049 316 10169 2047 169 9502 207 119 54216 2652 10435 25949 13268 3520 5395 2120 10124 4881 2678 2648 5139 22185 63952 3085 4473 42767 3520 5139 12416 119 5505 10944 5097 207 2083 7456 18240 316 2332 3787 376 5139 5395 2120 3258 2223 2091 119 17116 12807 2283 169 18444 2917 376 2821 18444 2917 13268 6449 5139 2083 7456 18240 11337 38356 2944 5097 169 3044 3520 21053 30434 12998 24132 2123 2332 4815 2410 3721 119 5505 10944 6894 11039 405 169 5996 4467 5139 12416 2105 12935 64312 2652 11661 316 117 23447 13903 10376 50915 2069 50995 2821 8466 105111 12998 24132 2123 119 11723 10301 10181 207 11661 316 2767 13961 119 5505 10944 10911 2111 10751 6449 21051 12141 11426 2283 5139 50915 11858 119 5505 10944 2904 3179 3044 2016 2332 11839 6449 2083 207 3967 316 119 16483 117 5139 2218 10124 169 5996 3520 11989 4467 5139 12416 11049 9488 13893 111006 10376 117 12541 504 3787 13971 6449 9205 102 14962 5058 405 12126 3085 4473 42767 316 3520 5139 12416 10301 31311 2091 5121 9860 2283 5139 168 4873 98541 136 15139 119 102\n",
            "06/12/2019 21:01:46 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "06/12/2019 21:01:46 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "06/12/2019 21:01:46 - INFO - __main__ -   choice: 1\n",
            "06/12/2019 21:01:46 - INFO - __main__ -   tokens: [CLS] In the e ##arl ##y 1990 ##s , the wor ##d \" Internet \" was stran ##ge to most people . But to ##day , Internet has be ##come a us ##ef ##ul to ##ol for people all over the world . May ##be Internet has be ##en the gre ##ates ##t invent ##ion in the field of commu ##nica ##tion in the history of man ##kin ##d . Communic ##ating with ot ##her ##s on the Internet is much fast ##er . We can chat with a person wh ##o is sit ##ting in the ot ##her part of the world . We can e - mail our fr ##ien ##ds and the ##y can re ##ad the e - mail ##s with ##in a minut ##e . Giv ##ing all kin ##ds of informa ##tion is prob ##ab ##ly the big ##gest ad ##van ##tage of the Internet . We can us ##e se ##arch engine ##s to fin ##d the informa ##tion we ne ##ed . Just type in a key ##wor ##d or key ##wor ##ds and the se ##arch engine will gi ##ve us a list of sui ##table web ##sit ##es to lo ##ok at . We can en ##jo ##y a lot on the Internet by down ##load ##ing game ##s , vis ##iti ##ng chat ro ##oms or sur ##fing web ##sit ##es . There are som ##e game ##s for free . We can me ##et new and interes ##ting people in the chat now . We can al ##so list ##en to music and se ##e film ##s . Now , the ##re is a lot of service on the Internet such as online banki ##ng , jo ##b fin ##ding and ti [SEP] How man ##y main ad ##van ##tage ##s of the Internet are talk ##ed ab ##out in the _ pas ##sage ? Four . [SEP]\n",
            "06/12/2019 21:01:46 - INFO - __main__ -   input_ids: 101 2762 5139 173 43278 405 3692 316 117 5139 39360 376 107 12416 107 10134 3459 3175 2332 7821 11426 119 16976 2332 24558 117 12416 10393 10347 61643 169 5097 3756 2355 2332 2098 2767 11426 10435 10491 5139 11356 119 10725 5446 12416 10393 10347 2016 5139 39819 26171 312 100910 5165 2283 5139 13939 3520 106036 6339 2120 2283 5139 11486 3520 5058 12130 376 119 64336 33121 10169 3033 4806 316 4467 5139 12416 10124 13172 15040 2030 119 5505 10944 50915 10169 169 15042 101396 203 10124 19285 12141 2283 5139 3033 4806 8647 3520 5139 11356 119 5505 10944 173 118 30049 17446 12127 3579 13268 6449 5139 405 10944 2261 2070 5139 173 118 30049 316 10169 2047 169 9502 207 119 54216 2652 10435 25949 13268 3520 5395 2120 10124 4881 2678 2648 5139 22185 63952 3085 4473 42767 3520 5139 12416 119 5505 10944 5097 207 2083 7456 18240 316 2332 3787 376 5139 5395 2120 3258 2223 2091 119 17116 12807 2283 169 18444 2917 376 2821 18444 2917 13268 6449 5139 2083 7456 18240 11337 38356 2944 5097 169 3044 3520 21053 30434 12998 24132 2123 2332 4815 2410 3721 119 5505 10944 6894 11039 405 169 5996 4467 5139 12416 2105 12935 64312 2652 11661 316 117 23447 13903 10376 50915 2069 50995 2821 8466 105111 12998 24132 2123 119 11723 10301 10181 207 11661 316 2767 13961 119 5505 10944 10911 2111 10751 6449 21051 12141 11426 2283 5139 50915 11858 119 5505 10944 2904 3179 3044 2016 2332 11839 6449 2083 207 3967 316 119 16483 117 5139 2218 10124 169 5996 3520 11989 4467 5139 12416 11049 9488 13893 111006 10376 117 12541 504 3787 13971 6449 9205 102 14962 5058 405 12126 3085 4473 42767 316 3520 5139 12416 10301 31311 2091 5121 9860 2283 5139 168 4873 98541 136 16773 119 102\n",
            "06/12/2019 21:01:46 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "06/12/2019 21:01:46 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "06/12/2019 21:01:46 - INFO - __main__ -   choice: 2\n",
            "06/12/2019 21:01:46 - INFO - __main__ -   tokens: [CLS] In the e ##arl ##y 1990 ##s , the wor ##d \" Internet \" was stran ##ge to most people . But to ##day , Internet has be ##come a us ##ef ##ul to ##ol for people all over the world . May ##be Internet has be ##en the gre ##ates ##t invent ##ion in the field of commu ##nica ##tion in the history of man ##kin ##d . Communic ##ating with ot ##her ##s on the Internet is much fast ##er . We can chat with a person wh ##o is sit ##ting in the ot ##her part of the world . We can e - mail our fr ##ien ##ds and the ##y can re ##ad the e - mail ##s with ##in a minut ##e . Giv ##ing all kin ##ds of informa ##tion is prob ##ab ##ly the big ##gest ad ##van ##tage of the Internet . We can us ##e se ##arch engine ##s to fin ##d the informa ##tion we ne ##ed . Just type in a key ##wor ##d or key ##wor ##ds and the se ##arch engine will gi ##ve us a list of sui ##table web ##sit ##es to lo ##ok at . We can en ##jo ##y a lot on the Internet by down ##load ##ing game ##s , vis ##iti ##ng chat ro ##oms or sur ##fing web ##sit ##es . There are som ##e game ##s for free . We can me ##et new and interes ##ting people in the chat now . We can al ##so list ##en to music and se ##e film ##s . Now , the ##re is a lot of service on the Internet such as online banki ##ng , jo ##b fin ##ding and ti [SEP] How man ##y main ad ##van ##tage ##s of the Internet are talk ##ed ab ##out in the _ pas ##sage ? Five . [SEP]\n",
            "06/12/2019 21:01:46 - INFO - __main__ -   input_ids: 101 2762 5139 173 43278 405 3692 316 117 5139 39360 376 107 12416 107 10134 3459 3175 2332 7821 11426 119 16976 2332 24558 117 12416 10393 10347 61643 169 5097 3756 2355 2332 2098 2767 11426 10435 10491 5139 11356 119 10725 5446 12416 10393 10347 2016 5139 39819 26171 312 100910 5165 2283 5139 13939 3520 106036 6339 2120 2283 5139 11486 3520 5058 12130 376 119 64336 33121 10169 3033 4806 316 4467 5139 12416 10124 13172 15040 2030 119 5505 10944 50915 10169 169 15042 101396 203 10124 19285 12141 2283 5139 3033 4806 8647 3520 5139 11356 119 5505 10944 173 118 30049 17446 12127 3579 13268 6449 5139 405 10944 2261 2070 5139 173 118 30049 316 10169 2047 169 9502 207 119 54216 2652 10435 25949 13268 3520 5395 2120 10124 4881 2678 2648 5139 22185 63952 3085 4473 42767 3520 5139 12416 119 5505 10944 5097 207 2083 7456 18240 316 2332 3787 376 5139 5395 2120 3258 2223 2091 119 17116 12807 2283 169 18444 2917 376 2821 18444 2917 13268 6449 5139 2083 7456 18240 11337 38356 2944 5097 169 3044 3520 21053 30434 12998 24132 2123 2332 4815 2410 3721 119 5505 10944 6894 11039 405 169 5996 4467 5139 12416 2105 12935 64312 2652 11661 316 117 23447 13903 10376 50915 2069 50995 2821 8466 105111 12998 24132 2123 119 11723 10301 10181 207 11661 316 2767 13961 119 5505 10944 10911 2111 10751 6449 21051 12141 11426 2283 5139 50915 11858 119 5505 10944 2904 3179 3044 2016 2332 11839 6449 2083 207 3967 316 119 16483 117 5139 2218 10124 169 5996 3520 11989 4467 5139 12416 11049 9488 13893 111006 10376 117 12541 504 3787 13971 6449 9205 102 14962 5058 405 12126 3085 4473 42767 316 3520 5139 12416 10301 31311 2091 5121 9860 2283 5139 168 4873 98541 136 19268 119 102\n",
            "06/12/2019 21:01:46 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "06/12/2019 21:01:46 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "06/12/2019 21:01:46 - INFO - __main__ -   choice: 3\n",
            "06/12/2019 21:01:46 - INFO - __main__ -   tokens: [CLS] In the e ##arl ##y 1990 ##s , the wor ##d \" Internet \" was stran ##ge to most people . But to ##day , Internet has be ##come a us ##ef ##ul to ##ol for people all over the world . May ##be Internet has be ##en the gre ##ates ##t invent ##ion in the field of commu ##nica ##tion in the history of man ##kin ##d . Communic ##ating with ot ##her ##s on the Internet is much fast ##er . We can chat with a person wh ##o is sit ##ting in the ot ##her part of the world . We can e - mail our fr ##ien ##ds and the ##y can re ##ad the e - mail ##s with ##in a minut ##e . Giv ##ing all kin ##ds of informa ##tion is prob ##ab ##ly the big ##gest ad ##van ##tage of the Internet . We can us ##e se ##arch engine ##s to fin ##d the informa ##tion we ne ##ed . Just type in a key ##wor ##d or key ##wor ##ds and the se ##arch engine will gi ##ve us a list of sui ##table web ##sit ##es to lo ##ok at . We can en ##jo ##y a lot on the Internet by down ##load ##ing game ##s , vis ##iti ##ng chat ro ##oms or sur ##fing web ##sit ##es . There are som ##e game ##s for free . We can me ##et new and interes ##ting people in the chat now . We can al ##so list ##en to music and se ##e film ##s . Now , the ##re is a lot of service on the Internet such as online banki ##ng , jo ##b fin ##ding and ti [SEP] How man ##y main ad ##van ##tage ##s of the Internet are talk ##ed ab ##out in the _ pas ##sage ? Six . [SEP]\n",
            "06/12/2019 21:01:46 - INFO - __main__ -   input_ids: 101 2762 5139 173 43278 405 3692 316 117 5139 39360 376 107 12416 107 10134 3459 3175 2332 7821 11426 119 16976 2332 24558 117 12416 10393 10347 61643 169 5097 3756 2355 2332 2098 2767 11426 10435 10491 5139 11356 119 10725 5446 12416 10393 10347 2016 5139 39819 26171 312 100910 5165 2283 5139 13939 3520 106036 6339 2120 2283 5139 11486 3520 5058 12130 376 119 64336 33121 10169 3033 4806 316 4467 5139 12416 10124 13172 15040 2030 119 5505 10944 50915 10169 169 15042 101396 203 10124 19285 12141 2283 5139 3033 4806 8647 3520 5139 11356 119 5505 10944 173 118 30049 17446 12127 3579 13268 6449 5139 405 10944 2261 2070 5139 173 118 30049 316 10169 2047 169 9502 207 119 54216 2652 10435 25949 13268 3520 5395 2120 10124 4881 2678 2648 5139 22185 63952 3085 4473 42767 3520 5139 12416 119 5505 10944 5097 207 2083 7456 18240 316 2332 3787 376 5139 5395 2120 3258 2223 2091 119 17116 12807 2283 169 18444 2917 376 2821 18444 2917 13268 6449 5139 2083 7456 18240 11337 38356 2944 5097 169 3044 3520 21053 30434 12998 24132 2123 2332 4815 2410 3721 119 5505 10944 6894 11039 405 169 5996 4467 5139 12416 2105 12935 64312 2652 11661 316 117 23447 13903 10376 50915 2069 50995 2821 8466 105111 12998 24132 2123 119 11723 10301 10181 207 11661 316 2767 13961 119 5505 10944 10911 2111 10751 6449 21051 12141 11426 2283 5139 50915 11858 119 5505 10944 2904 3179 3044 2016 2332 11839 6449 2083 207 3967 316 119 16483 117 5139 2218 10124 169 5996 3520 11989 4467 5139 12416 11049 9488 13893 111006 10376 117 12541 504 3787 13971 6449 9205 102 14962 5058 405 12126 3085 4473 42767 316 3520 5139 12416 10301 31311 2091 5121 9860 2283 5139 168 4873 98541 136 20615 119 102\n",
            "06/12/2019 21:01:46 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "06/12/2019 21:01:46 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "06/12/2019 21:01:46 - INFO - __main__ -   label: 1\n",
            "06/12/2019 21:11:27 - INFO - __main__ -   ***** Running training *****\n",
            "06/12/2019 21:11:27 - INFO - __main__ -     Num examples = 87866\n",
            "06/12/2019 21:11:27 - INFO - __main__ -     Batch size = 4\n",
            "06/12/2019 21:11:27 - INFO - __main__ -     Num steps = 8237\n",
            "06/12/2019 21:11:34 - INFO - __main__ -   Trianing Epoch: 1/3\n",
            "06/12/2019 21:11:34 - INFO - __main__ -   Training loss: 21.515625, global step: 0\n",
            "06/12/2019 21:11:35 - INFO - __main__ -   Training loss: 20.859375, global step: 0\n",
            "06/12/2019 21:11:35 - INFO - __main__ -   Training loss: 22.052083333333332, global step: 0\n",
            "06/12/2019 21:11:35 - INFO - __main__ -   Training loss: 22.33203125, global step: 0\n",
            "06/12/2019 21:11:36 - INFO - __main__ -   Training loss: 22.453125, global step: 0\n",
            "06/12/2019 21:11:36 - INFO - __main__ -   Training loss: 22.424479166666668, global step: 0\n",
            "06/12/2019 21:11:36 - INFO - __main__ -   Training loss: 22.46875, global step: 0\n",
            "06/12/2019 21:16:34 - INFO - __main__ -   Training loss: 22.306171875, global step: 100\n",
            "06/12/2019 21:16:34 - INFO - __main__ -   Training loss: 22.306452871410738, global step: 100\n",
            "06/12/2019 21:16:34 - INFO - __main__ -   Training loss: 22.30626558603491, global step: 100\n",
            "06/12/2019 21:16:35 - INFO - __main__ -   Training loss: 22.30582580946451, global step: 100\n",
            "06/12/2019 21:16:35 - INFO - __main__ -   Training loss: 22.306417133084576, global step: 100\n",
            "06/12/2019 21:16:36 - INFO - __main__ -   Training loss: 22.30603649068323, global step: 100\n",
            "06/12/2019 21:16:36 - INFO - __main__ -   Training loss: 22.303873294044664, global step: 100\n",
            "06/12/2019 21:16:36 - INFO - __main__ -   Training loss: 22.301212050805454, global step: 100\n",
            "06/12/2019 21:21:50 - INFO - __main__ -   Training loss: 22.25890625, global step: 200\n",
            "06/12/2019 21:21:51 - INFO - __main__ -   Training loss: 22.258744534665833, global step: 200\n",
            "06/12/2019 21:21:51 - INFO - __main__ -   Training loss: 22.25910970661673, global step: 200\n",
            "06/12/2019 21:21:52 - INFO - __main__ -   Training loss: 22.25931846537742, global step: 200\n",
            "06/12/2019 21:21:52 - INFO - __main__ -   Training loss: 22.259000935162096, global step: 200\n",
            "06/12/2019 21:21:52 - INFO - __main__ -   Training loss: 22.258946651090344, global step: 200\n",
            "06/12/2019 21:21:53 - INFO - __main__ -   Training loss: 22.258357331880447, global step: 200\n",
            "06/12/2019 21:21:53 - INFO - __main__ -   Training loss: 22.258361854387058, global step: 200\n",
            "06/12/2019 21:27:07 - INFO - __main__ -   Training loss: 22.239915364583332, global step: 300\n",
            "06/12/2019 21:27:08 - INFO - __main__ -   Training loss: 22.239659256559765, global step: 300\n",
            "06/12/2019 21:27:08 - INFO - __main__ -   Training loss: 22.23889597210658, global step: 300\n",
            "06/12/2019 21:27:08 - INFO - __main__ -   Training loss: 22.238562473990847, global step: 300\n",
            "06/12/2019 21:27:09 - INFO - __main__ -   Training loss: 22.238853213394343, global step: 300\n",
            "06/12/2019 21:27:09 - INFO - __main__ -   Training loss: 22.238338097713097, global step: 300\n",
            "06/12/2019 21:27:10 - INFO - __main__ -   Training loss: 22.23800524729842, global step: 300\n",
            "06/12/2019 21:27:10 - INFO - __main__ -   Training loss: 22.23748442044038, global step: 300\n",
            "06/12/2019 21:32:24 - INFO - __main__ -   Training loss: 22.22767578125, global step: 400\n",
            "06/12/2019 21:32:24 - INFO - __main__ -   Training loss: 22.227672992814746, global step: 400\n",
            "06/12/2019 21:32:24 - INFO - __main__ -   Training loss: 22.227518933479075, global step: 400\n",
            "06/12/2019 21:32:25 - INFO - __main__ -   Training loss: 22.22757961286294, global step: 400\n",
            "06/12/2019 21:32:25 - INFO - __main__ -   Training loss: 22.227971871098628, global step: 400\n",
            "06/12/2019 21:32:26 - INFO - __main__ -   Training loss: 22.227515600624024, global step: 400\n",
            "06/12/2019 21:32:26 - INFO - __main__ -   Training loss: 22.22724968808484, global step: 400\n",
            "06/12/2019 21:32:26 - INFO - __main__ -   Training loss: 22.22716908325538, global step: 400\n",
            "06/12/2019 21:37:40 - INFO - __main__ -   Training loss: 22.1985234375, global step: 500\n",
            "06/12/2019 21:37:40 - INFO - __main__ -   Training loss: 22.19805204948763, global step: 500\n",
            "06/12/2019 21:37:41 - INFO - __main__ -   Training loss: 22.198674100449775, global step: 500\n",
            "06/12/2019 21:37:41 - INFO - __main__ -   Training loss: 22.198156070447165, global step: 500\n",
            "06/12/2019 21:37:42 - INFO - __main__ -   Training loss: 22.198032436313685, global step: 500\n",
            "06/12/2019 21:37:42 - INFO - __main__ -   Training loss: 22.19857599875156, global step: 500\n",
            "06/12/2019 21:37:42 - INFO - __main__ -   Training loss: 22.198600536694958, global step: 500\n",
            "06/12/2019 21:37:43 - INFO - __main__ -   Training loss: 22.198890223359122, global step: 500\n",
            "06/12/2019 21:42:58 - INFO - __main__ -   Training loss: 22.146638997395833, global step: 600\n",
            "06/12/2019 21:42:58 - INFO - __main__ -   Training loss: 22.146130038012913, global step: 600\n",
            "06/12/2019 21:42:59 - INFO - __main__ -   Training loss: 22.14618746095377, global step: 600\n",
            "06/12/2019 21:42:59 - INFO - __main__ -   Training loss: 22.14610497345409, global step: 600\n",
            "06/12/2019 21:43:00 - INFO - __main__ -   Training loss: 22.1458306229184, global step: 600\n",
            "06/12/2019 21:43:00 - INFO - __main__ -   Training loss: 22.1458718132154, global step: 600\n",
            "06/12/2019 21:43:00 - INFO - __main__ -   Training loss: 22.145769936017476, global step: 600\n",
            "06/12/2019 21:43:01 - INFO - __main__ -   Training loss: 22.145268293634285, global step: 600\n",
            "06/12/2019 21:48:14 - INFO - __main__ -   Training loss: 22.121192801339287, global step: 700\n",
            "06/12/2019 21:48:15 - INFO - __main__ -   Training loss: 22.120822453579716, global step: 700\n",
            "06/12/2019 21:48:15 - INFO - __main__ -   Training loss: 22.120867826222778, global step: 700\n",
            "06/12/2019 21:48:15 - INFO - __main__ -   Training loss: 22.12038890995895, global step: 700\n",
            "06/12/2019 21:48:16 - INFO - __main__ -   Training loss: 22.120247535242683, global step: 700\n",
            "06/12/2019 21:48:16 - INFO - __main__ -   Training loss: 22.119902709634257, global step: 700\n",
            "06/12/2019 21:48:17 - INFO - __main__ -   Training loss: 22.12043318542633, global step: 700\n",
            "06/12/2019 21:48:17 - INFO - __main__ -   Training loss: 22.120297451845907, global step: 700\n",
            "06/12/2019 21:53:30 - INFO - __main__ -   Training loss: 22.103363037109375, global step: 800\n",
            "06/12/2019 21:53:31 - INFO - __main__ -   Training loss: 22.102997822605843, global step: 800\n",
            "06/12/2019 21:53:31 - INFO - __main__ -   Training loss: 22.10296220907529, global step: 800\n",
            "06/12/2019 21:53:31 - INFO - __main__ -   Training loss: 22.103229199203497, global step: 800\n",
            "06/12/2019 21:53:32 - INFO - __main__ -   Training loss: 22.10340339045909, global step: 800\n",
            "06/12/2019 21:53:32 - INFO - __main__ -   Training loss: 22.103582406323184, global step: 800\n",
            "06/12/2019 21:53:33 - INFO - __main__ -   Training loss: 22.10374673157977, global step: 800\n",
            "06/12/2019 21:53:33 - INFO - __main__ -   Training loss: 22.103452522631496, global step: 800\n",
            "06/12/2019 21:58:46 - INFO - __main__ -   Training loss: 22.097099609375, global step: 900\n",
            "06/12/2019 21:58:46 - INFO - __main__ -   Training loss: 22.09646338182197, global step: 900\n",
            "06/12/2019 21:58:47 - INFO - __main__ -   Training loss: 22.096499887184116, global step: 900\n",
            "06/12/2019 21:58:47 - INFO - __main__ -   Training loss: 22.096666536512565, global step: 900\n",
            "06/12/2019 21:58:48 - INFO - __main__ -   Training loss: 22.096904714394782, global step: 900\n",
            "06/12/2019 21:58:48 - INFO - __main__ -   Training loss: 22.097017045454546, global step: 900\n",
            "06/12/2019 21:58:48 - INFO - __main__ -   Training loss: 22.097250771926173, global step: 900\n",
            "06/12/2019 21:58:49 - INFO - __main__ -   Training loss: 22.097209093589566, global step: 900\n",
            "06/12/2019 22:04:01 - INFO - __main__ -   Training loss: 22.08150390625, global step: 1000\n",
            "06/12/2019 22:04:02 - INFO - __main__ -   Training loss: 22.081692913385826, global step: 1000\n",
            "06/12/2019 22:04:02 - INFO - __main__ -   Training loss: 22.081645604223944, global step: 1000\n",
            "06/12/2019 22:04:03 - INFO - __main__ -   Training loss: 22.08146749656379, global step: 1000\n",
            "06/12/2019 22:04:03 - INFO - __main__ -   Training loss: 22.081332380684657, global step: 1000\n",
            "06/12/2019 22:04:03 - INFO - __main__ -   Training loss: 22.08116021236727, global step: 1000\n",
            "06/12/2019 22:04:04 - INFO - __main__ -   Training loss: 22.08091392393205, global step: 1000\n",
            "06/12/2019 22:04:04 - INFO - __main__ -   Training loss: 22.081075543274636, global step: 1000\n",
            "06/12/2019 22:09:18 - INFO - __main__ -   Training loss: 22.060578835227272, global step: 1100\n",
            "06/12/2019 22:09:18 - INFO - __main__ -   Training loss: 22.06016716850358, global step: 1100\n",
            "06/12/2019 22:09:18 - INFO - __main__ -   Training loss: 22.060936079868213, global step: 1100\n",
            "06/12/2019 22:09:19 - INFO - __main__ -   Training loss: 22.061214926729523, global step: 1100\n",
            "06/12/2019 22:09:19 - INFO - __main__ -   Training loss: 22.061048245115856, global step: 1100\n",
            "06/12/2019 22:09:20 - INFO - __main__ -   Training loss: 22.061098097671778, global step: 1100\n",
            "06/12/2019 22:09:20 - INFO - __main__ -   Training loss: 22.06103792868499, global step: 1100\n",
            "06/12/2019 22:09:20 - INFO - __main__ -   Training loss: 22.060885517202227, global step: 1100\n",
            "06/12/2019 22:14:33 - INFO - __main__ -   Training loss: 22.051517740885416, global step: 1200\n",
            "06/12/2019 22:14:33 - INFO - __main__ -   Training loss: 22.05171092203937, global step: 1200\n",
            "06/12/2019 22:14:34 - INFO - __main__ -   Training loss: 22.05149073760675, global step: 1200\n",
            "06/12/2019 22:14:34 - INFO - __main__ -   Training loss: 22.051792896751014, global step: 1200\n",
            "06/12/2019 22:14:34 - INFO - __main__ -   Training loss: 22.051841192471887, global step: 1200\n",
            "06/12/2019 22:14:35 - INFO - __main__ -   Training loss: 22.051796752993233, global step: 1200\n",
            "06/12/2019 22:14:35 - INFO - __main__ -   Training loss: 22.051383087393297, global step: 1200\n",
            "06/12/2019 22:14:36 - INFO - __main__ -   Training loss: 22.051551765639637, global step: 1200\n",
            "06/12/2019 22:19:49 - INFO - __main__ -   Training loss: 22.036600060096156, global step: 1300\n",
            "06/12/2019 22:19:49 - INFO - __main__ -   Training loss: 22.036626586385925, global step: 1300\n",
            "06/12/2019 22:19:50 - INFO - __main__ -   Training loss: 22.03650740242261, global step: 1300\n",
            "06/12/2019 22:19:50 - INFO - __main__ -   Training loss: 22.036383735460923, global step: 1300\n",
            "06/12/2019 22:19:51 - INFO - __main__ -   Training loss: 22.036207528354478, global step: 1300\n",
            "06/12/2019 22:19:51 - INFO - __main__ -   Training loss: 22.035975792888035, global step: 1300\n",
            "06/12/2019 22:19:51 - INFO - __main__ -   Training loss: 22.03578164039977, global step: 1300\n",
            "06/12/2019 22:19:52 - INFO - __main__ -   Training loss: 22.035821742577113, global step: 1300\n",
            "06/12/2019 22:25:05 - INFO - __main__ -   Training loss: 22.018884626116073, global step: 1400\n",
            "06/12/2019 22:25:05 - INFO - __main__ -   Training loss: 22.018912234398716, global step: 1400\n",
            "06/12/2019 22:25:06 - INFO - __main__ -   Training loss: 22.018858937020173, global step: 1400\n",
            "06/12/2019 22:25:06 - INFO - __main__ -   Training loss: 22.019012067080247, global step: 1400\n",
            "06/12/2019 22:25:07 - INFO - __main__ -   Training loss: 22.018976899991074, global step: 1400\n",
            "06/12/2019 22:25:07 - INFO - __main__ -   Training loss: 22.01912162539045, global step: 1400\n",
            "06/12/2019 22:25:07 - INFO - __main__ -   Training loss: 22.019170115339996, global step: 1400\n",
            "06/12/2019 22:25:08 - INFO - __main__ -   Training loss: 22.019240904122423, global step: 1400\n",
            "06/12/2019 22:30:21 - INFO - __main__ -   Training loss: 21.996751953125, global step: 1500\n",
            "06/12/2019 22:30:21 - INFO - __main__ -   Training loss: 21.996952727897675, global step: 1500\n",
            "06/12/2019 22:30:21 - INFO - __main__ -   Training loss: 21.99686966234794, global step: 1500\n",
            "06/12/2019 22:30:22 - INFO - __main__ -   Training loss: 21.99712246417562, global step: 1500\n",
            "06/12/2019 22:30:22 - INFO - __main__ -   Training loss: 21.997169563270578, global step: 1500\n",
            "06/12/2019 22:30:23 - INFO - __main__ -   Training loss: 21.997255700749687, global step: 1500\n",
            "06/12/2019 22:30:23 - INFO - __main__ -   Training loss: 21.99735744107113, global step: 1500\n",
            "06/12/2019 22:30:23 - INFO - __main__ -   Training loss: 21.99753724389939, global step: 1500\n",
            "06/12/2019 22:35:36 - INFO - __main__ -   Training loss: 21.9769580078125, global step: 1600\n",
            "06/12/2019 22:35:36 - INFO - __main__ -   Training loss: 21.977157546285447, global step: 1600\n",
            "06/12/2019 22:35:37 - INFO - __main__ -   Training loss: 21.977028735744415, global step: 1600\n",
            "06/12/2019 22:35:37 - INFO - __main__ -   Training loss: 21.977092771225493, global step: 1600\n",
            "06/12/2019 22:35:37 - INFO - __main__ -   Training loss: 21.97717998281787, global step: 1600\n",
            "06/12/2019 22:35:38 - INFO - __main__ -   Training loss: 21.976898672393595, global step: 1600\n",
            "06/12/2019 22:35:38 - INFO - __main__ -   Training loss: 21.97697124394815, global step: 1600\n",
            "06/12/2019 22:35:39 - INFO - __main__ -   Training loss: 21.976897399859453, global step: 1600\n",
            "06/12/2019 22:40:52 - INFO - __main__ -   Training loss: 21.955348690257352, global step: 1700\n",
            "06/12/2019 22:40:53 - INFO - __main__ -   Training loss: 21.955253175317992, global step: 1700\n",
            "06/12/2019 22:40:53 - INFO - __main__ -   Training loss: 21.955296670526394, global step: 1700\n",
            "06/12/2019 22:40:54 - INFO - __main__ -   Training loss: 21.95530914596045, global step: 1700\n",
            "06/12/2019 22:40:54 - INFO - __main__ -   Training loss: 21.955126364488386, global step: 1700\n",
            "06/12/2019 22:40:54 - INFO - __main__ -   Training loss: 21.955306527930908, global step: 1700\n",
            "06/12/2019 22:40:55 - INFO - __main__ -   Training loss: 21.955300625643098, global step: 1700\n",
            "06/12/2019 22:40:55 - INFO - __main__ -   Training loss: 21.95515463088851, global step: 1700\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFsCBGLV6a_Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!python BERT-RACE/run_race.py --data_dir=RACE --bert_model=bg_cs_pl_ru_cased_L-12_H-768_A-12/ --output_dir=./slavic_models_2_epochs --max_seq_length=320 --do_train --do_eval --train_batch_size=32 --eval_batch_size=1 --learning_rate=1e-3 --num_train_epochs=2 --gradient_accumulation_steps=8 --fp16 --loss_scale=128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPhh5RT0FCkm",
        "colab_type": "text"
      },
      "source": [
        "Downloading the models:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBX4feGXDmso",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "#!tar -cvf slavic_models_3_epochs.tar slavic_models_3_epochs\n",
        "#files.download('slavic_models_3_epochs.tar')\n",
        "\n",
        "!tar -cvf slavic_models_3_epochs_1e-5.tar slavic_models_3_epochs_1e-5\n",
        "files.download('slavic_models_3_epochs_1e-5.tar')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ku2SYnTcEjl6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}